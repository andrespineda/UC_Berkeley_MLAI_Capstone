{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessor that reads in the WESAD datasets.\n",
"WESAD (Wearable Stress and Affect Detection) contains data of 15 subjects during a stress-affect lab study, while wearing physiological and motion sensors. WESAD is a publicly available dataset for wearable stress and affect detection. This multimodal dataset features physiological and motion data, recorded from both a wrist- and a chest-worn device, of 15 subjects during a lab study. The following sensor modalities are included: blood volume pulse, electrocardiogram, electrodermal activity, electromyogram, respiration, body temperature, and three-axis acceleration. Moreover, the dataset bridges the gap between previous lab studies on stress and emotions, by containing three different affective states (neutral, stress, amusement). In addition, self-reports of the subjects, which were obtained using several established questionnaires, are contained in the dataset.(Schmidt, et.al., 2018)",

 "The original paper and links to download the dataset can be found via this link: https://archive.ics.uci.edu/dataset/465/wesad+wearable+stress+and+affect+detection"
        "The files are in pickle format, so they must be read in and combined into one file"
      ],
      "metadata": {
        "id": "V3w0Zwad8vlT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wx6X4GkromrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9b9df6-21ac-4329-ce48-88bafd2b06d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "processing file:  /content/drive/MyDrive/Capstone/WESAD/S2/S2.pkl\n",
            "merged_data.shape:  (4255300, 10)\n",
            "\n",
            "processing file:  /content/drive/MyDrive/Capstone/WESAD/S3/S3.pkl\n",
            "last_subj.shape:  (4545100, 10)\n",
            "merged_data.shape:  (8800400, 10)\n",
            "\n",
            "processing file:  /content/drive/MyDrive/Capstone/WESAD/S4/S4.pkl\n",
            "last_subj.shape:  (4496100, 10)\n",
            "merged_data.shape:  (13296500, 10)\n",
            "\n",
            "processing file:  /content/drive/MyDrive/Capstone/WESAD/S5/S5.pkl\n",
            "last_subj.shape:  (4380600, 10)\n",
            "merged_data.shape:  (17677100, 10)\n",
            "\n",
            "processing file:  /content/drive/MyDrive/Capstone/WESAD/S6/S6.pkl\n",
            "last_subj.shape:  (4949700, 10)\n",
            "merged_data.shape:  (22626800, 10)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "\n",
        "\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/Capstone/WESAD/'\n",
        "\n",
        "chest_columns=['sid', 'acc1', 'acc2', 'acc3', 'ecg', 'emg', 'eda', 'temp', 'resp', 'label']\n",
        "all_columns =['sid', 'c_acc_x', 'c_acc_y', 'c_acc_z', 'ecg', 'emg', 'c_eda', 'c_temp', 'resp', 'w_acc_x' , 'w_acc_y', 'w_acc_z', 'bvp', 'w_eda', 'w_temp', 'label']\n",
        "ids = [2,3,4,5,6]\n",
        "\n",
        "\n",
        "\n",
        "sf_BVP = 64\n",
        "sf_EDA = 4\n",
        "sf_TEMP = 4\n",
        "sf_ACC = 32\n",
        "sf_chest = 700\n",
        "\n",
        "\n",
        "\n",
        "# convert data from pickle dictionary format to dataframe for wrist\n",
        "def pkl_to_np_wrist(filename, subject_id):\n",
        "    unpickled_df = pd.read_pickle(filename)\n",
        "    wrist_acc = unpickled_df[\"signal\"][\"wrist\"][\"ACC\"]\n",
        "    wrist_bvp = unpickled_df[\"signal\"][\"wrist\"][\"BVP\"]\n",
        "    wrist_eda = unpickled_df[\"signal\"][\"wrist\"][\"EDA\"]\n",
        "    wrist_temp = unpickled_df[\"signal\"][\"wrist\"][\"TEMP\"]\n",
        "    lbl = unpickled_df[\"label\"].reshape(unpickled_df[\"label\"].shape[0],1)\n",
        "\n",
        "    n_wrist_acc = len(wrist_acc)\n",
        "    n_wrist_bvp = len(wrist_bvp)\n",
        "    n_wrist_eda = len(wrist_eda)\n",
        "    n_wrist_temp = len(wrist_temp)\n",
        "\n",
        "    print(\"wrist_bvp shape: \", wrist_bvp.shape)\n",
        "    print(\"wrist_eda shape: \", wrist_eda.shape)\n",
        "    print(\"wrist_temp shape: \", wrist_temp.shape)\n",
        "    print(\"wrist_acc shape: \", wrist_acc.shape)\n",
        "\n",
        "\n",
        "\n",
        "    sid_acc = np.repeat(subject_id, n_wrist_acc).reshape((n_wrist_acc,1))\n",
        "    #lbl_acc = signal.resample(lbl, n_wrist_acc)\n",
        "    batch_size = sf_chest/sf_ACC\n",
        "    lbl_m = np.zeros((n_wrist_acc,1))\n",
        "    for i in range(n_wrist_acc):\n",
        "        lbl_m[i] = (stats.mode(lbl[round(i * batch_size) : round((i + 1) * batch_size) - 1]))[0].squeeze()\n",
        "    lbl_acc = lbl_m\n",
        "    print(\"lbl_acc.shape :\", lbl_acc.shape)\n",
        "\n",
        "\n",
        "    sid_bvp = np.repeat(subject_id, n_wrist_bvp).reshape((n_wrist_bvp,1))\n",
        "    #lbl_bvp = signal.resample(lbl, n_wrist_bvp)\n",
        "    batch_size = sf_chest/sf_BVP\n",
        "    lbl_m = np.zeros((n_wrist_bvp,1))\n",
        "    for i in range(n_wrist_bvp):\n",
        "        lbl_m[i] = (stats.mode(lbl[round(i * batch_size) : round((i + 1) * batch_size) - 1]))[0].squeeze()\n",
        "    lbl_bvp = lbl_m\n",
        "    print(\"lbl_bvp.shape :\", lbl_bvp.shape)\n",
        "\n",
        "    sid_eda_temp = np.repeat(subject_id, n_wrist_eda).reshape((n_wrist_eda,1))\n",
        "    #lbl_eda_temp = signal.resample(lbl, n_wrist_eda)\n",
        "    batch_size = sf_chest/sf_EDA\n",
        "    lbl_m = np.zeros((n_wrist_eda,1))\n",
        "    for i in range(n_wrist_eda):\n",
        "        lbl_m[i] = (stats.mode(lbl[round(i * batch_size) : round((i + 1) * batch_size) - 1]))[0].squeeze()\n",
        "    lbl_eda_temp = lbl_m\n",
        "    print(\"lbl_eda_temp.shape :\", lbl_eda_temp.shape)\n",
        "\n",
        "\n",
        "    data1 = np.concatenate((sid_acc, wrist_acc, lbl_acc), axis=1)\n",
        "    data2 = np.concatenate((sid_bvp, wrist_bvp, lbl_bvp), axis=1)\n",
        "    data3 = np.concatenate((sid_eda_temp, wrist_eda, wrist_temp, lbl_eda_temp), axis=1)\n",
        "\n",
        "    return data1, data2, data3\n",
        "\n",
        "\n",
        "\n",
        "def merge_wrist_data():\n",
        "    for i, sid in enumerate(ids):\n",
        "        file = DATA_PATH + 'S' + str(sid) + '/S' + str(sid) + '.pkl'\n",
        "        print(\"\")\n",
        "        print(\"processing file: \", file)\n",
        "        if i == 0:\n",
        "            md1, md2, md3 = pkl_to_np_wrist(file, sid)\n",
        "            print(\"md1.shape: \", md1.shape)\n",
        "            print(\"md2.shape: \", md2.shape)\n",
        "            print(\"md3.shape: \", md3.shape)\n",
        "        else:\n",
        "            last_subj1, last_subj2, last_subj3 = pkl_to_np_wrist(file, sid)\n",
        "            print(\"last_subj1.shape: \",last_subj1.shape)\n",
        "            print(\"last_subj2.shape: \",last_subj2.shape)\n",
        "            print(\"last_subj3.shape: \",last_subj3.shape)\n",
        "            md1 = np.concatenate((md1, last_subj1), axis=0)\n",
        "            md2 = np.concatenate((md2, last_subj2), axis=0)\n",
        "            md3 = np.concatenate((md3, last_subj3), axis=0)\n",
        "            print(\"md1.shape: \", md1.shape)\n",
        "            print(\"md2.shape: \", md2.shape)\n",
        "            print(\"md3.shape: \", md3.shape)\n",
        "\n",
        "    fn_merged1 = 'data/subj_merged_acc_w.pkl'\n",
        "    fn_merged2 = 'data/subj_merged_bvp_w.pkl'\n",
        "    fn_merged3 = 'data/subj_merged_eda_temp_w.pkl'\n",
        "    all_columns1 = ['sid', 'w_acc_x' , 'w_acc_y', 'w_acc_z', 'label']\n",
        "    all_columns2 = ['sid', 'bvp', 'label']\n",
        "    all_columns3 = ['sid', 'w_eda' , 'w_temp', 'label']\n",
        "    pd.DataFrame(md1, columns=all_columns1).to_pickle(fn_merged1)\n",
        "    pd.DataFrame(md2, columns=all_columns2).to_pickle(fn_merged2)\n",
        "    pd.DataFrame(md3, columns=all_columns3).to_pickle(fn_merged3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# convert data from pickle dictionary format to dataframe\n",
        "def pkl_to_np_chest(filename, subject_id):\n",
        "    unpickled_df = pd.read_pickle(filename)\n",
        "    chest_acc = unpickled_df[\"signal\"][\"chest\"][\"ACC\"]\n",
        "    chest_ecg = unpickled_df[\"signal\"][\"chest\"][\"ECG\"]\n",
        "    chest_emg = unpickled_df[\"signal\"][\"chest\"][\"EMG\"]\n",
        "    chest_eda = unpickled_df[\"signal\"][\"chest\"][\"EDA\"]\n",
        "    chest_temp = unpickled_df[\"signal\"][\"chest\"][\"Temp\"]\n",
        "    chest_resp = unpickled_df[\"signal\"][\"chest\"][\"Resp\"]\n",
        "    lbl = unpickled_df[\"label\"].reshape(unpickled_df[\"label\"].shape[0],1)\n",
        "    sid = np.full((lbl.shape[0],1), subject_id)\n",
        "    chest_all = np.concatenate((sid, chest_acc,chest_ecg, chest_emg,chest_eda, chest_temp,chest_resp, lbl), axis=1)\n",
        "    #new_fn = 'chest_all_' + filename\n",
        "    #pd.DataFrame(chest_all, columns=['acc1', 'acc2', 'acc3', 'ecg', 'emg', 'eda', 'temp', 'resp', 'label']).to_pickle(new_fn)\n",
        "    return chest_all\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def merge_chest_data():\n",
        "    for i, sid in enumerate(ids):\n",
        "        file = DATA_PATH + 'S' + str(sid) + '/S' + str(sid) + '.pkl'\n",
        "        print(\"\")\n",
        "        print(\"processing file: \", file)\n",
        "        if i == 0:\n",
        "            merged_data = pkl_to_np_chest(file, sid)\n",
        "            print(\"merged_data.shape: \", merged_data.shape)\n",
        "        else:\n",
        "            last_subj = pkl_to_np_chest(file, sid)\n",
        "            print(\"last_subj.shape: \",last_subj.shape)\n",
        "            merged_data = np.concatenate((merged_data, last_subj), axis=0)\n",
        "            print(\"merged_data.shape: \", merged_data.shape)\n",
        "\n",
        "    fn_merged = '/content/data/merged_chest.pkl'\n",
        "    pd.DataFrame(merged_data, columns=chest_columns).to_pickle(fn_merged)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def filter_chest_data():\n",
        "    df = pd.read_pickle((\"/content/data/merged_chest.pkl\"))\n",
        "    df_fltr = df[df[\"label\"].isin([1,2,3])]\n",
        "    df_fltr = df_fltr[df_fltr[\"temp\"]>0]\n",
        "    pd.DataFrame(df_fltr, columns=chest_columns).to_pickle(\"/content/data/merged_chest_fltr.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "def preprocess():\n",
        "   # merge_wrist_data()\n",
        "    merge_chest_data()\n",
        "    filter_chest_data()\n",
        "\n",
        "preprocess()"
      ]
    }
  ]
}
